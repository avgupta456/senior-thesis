{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9f930a",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab1594f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhijit\\Documents\\GitHub\\cpsc490\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import statistics\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import SNAPDataset, DBLP, IMDB\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, GINConv, to_hetero\n",
    "from torch_geometric.utils import negative_sampling, to_networkx\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a66043",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9d6bbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovie\u001b[0m={\n",
       "    x=[4278, 3066],\n",
       "    y=[4278],\n",
       "    train_mask=[4278],\n",
       "    val_mask=[4278],\n",
       "    test_mask=[4278]\n",
       "  },\n",
       "  \u001b[1mdirector\u001b[0m={ x=[2081, 3066] },\n",
       "  \u001b[1mactor\u001b[0m={ x=[5257, 3066] },\n",
       "  \u001b[1m(movie, to, director)\u001b[0m={ edge_index=[2, 4278] },\n",
       "  \u001b[1m(movie, to, actor)\u001b[0m={ edge_index=[2, 12828] },\n",
       "  \u001b[1m(director, to, movie)\u001b[0m={ edge_index=[2, 4278] },\n",
       "  \u001b[1m(actor, to, movie)\u001b[0m={ edge_index=[2, 12828] }\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB(root=\"../data/IMDB\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c28bc0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.ToDevice(device),\n",
    "    T.RemoveIsolatedNodes(),\n",
    "    T.RandomLinkSplit(\n",
    "        num_val=0.05, \n",
    "        num_test=0.1, \n",
    "        is_undirected=True, \n",
    "        add_negative_train_samples=False,\n",
    "        edge_types=[(\"movie\", \"to\", \"actor\")]\n",
    "    ),\n",
    "    T.ToUndirected(),\n",
    "])\n",
    "\n",
    "dataset = IMDB(root=\"../data/IMDB\", transform=transform)\n",
    "\n",
    "train_data, val_data, test_data = dataset[0]\n",
    "\n",
    "for data in train_data, val_data, test_data:\n",
    "    del data[(\"director\", \"to\", \"movie\")]\n",
    "    del data[(\"actor\", \"to\", \"movie\")]\n",
    "    \n",
    "    del data[(\"movie\", \"rev_to\", \"director\")]\n",
    "    del data[(\"movie\", \"rev_to\", \"actor\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e0ba2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1mmovie\u001b[0m={\n",
      "    x=[4278, 3066],\n",
      "    y=[4278],\n",
      "    train_mask=[4278],\n",
      "    val_mask=[4278],\n",
      "    test_mask=[4278]\n",
      "  },\n",
      "  \u001b[1mdirector\u001b[0m={ x=[2081, 3066] },\n",
      "  \u001b[1mactor\u001b[0m={ x=[5257, 3066] },\n",
      "  \u001b[1m(movie, to, director)\u001b[0m={ edge_index=[2, 4278] },\n",
      "  \u001b[1m(movie, to, actor)\u001b[0m={\n",
      "    edge_index=[2, 10905],\n",
      "    edge_label=[10905],\n",
      "    edge_label_index=[2, 10905]\n",
      "  },\n",
      "  \u001b[1m(director, rev_to, movie)\u001b[0m={ edge_index=[2, 4278] },\n",
      "  \u001b[1m(actor, rev_to, movie)\u001b[0m={\n",
      "    edge_index=[2, 10905],\n",
      "    edge_label=[10905]\n",
      "  }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mmovie\u001b[0m={\n",
      "    x=[4278, 3066],\n",
      "    y=[4278],\n",
      "    train_mask=[4278],\n",
      "    val_mask=[4278],\n",
      "    test_mask=[4278]\n",
      "  },\n",
      "  \u001b[1mdirector\u001b[0m={ x=[2081, 3066] },\n",
      "  \u001b[1mactor\u001b[0m={ x=[5257, 3066] },\n",
      "  \u001b[1m(movie, to, director)\u001b[0m={ edge_index=[2, 4278] },\n",
      "  \u001b[1m(movie, to, actor)\u001b[0m={\n",
      "    edge_index=[2, 10905],\n",
      "    edge_label=[1282],\n",
      "    edge_label_index=[2, 1282]\n",
      "  },\n",
      "  \u001b[1m(director, rev_to, movie)\u001b[0m={ edge_index=[2, 4278] },\n",
      "  \u001b[1m(actor, rev_to, movie)\u001b[0m={ edge_index=[2, 10905] }\n",
      ")\n",
      "HeteroData(\n",
      "  \u001b[1mmovie\u001b[0m={\n",
      "    x=[4278, 3066],\n",
      "    y=[4278],\n",
      "    train_mask=[4278],\n",
      "    val_mask=[4278],\n",
      "    test_mask=[4278]\n",
      "  },\n",
      "  \u001b[1mdirector\u001b[0m={ x=[2081, 3066] },\n",
      "  \u001b[1mactor\u001b[0m={ x=[5257, 3066] },\n",
      "  \u001b[1m(movie, to, director)\u001b[0m={ edge_index=[2, 4278] },\n",
      "  \u001b[1m(movie, to, actor)\u001b[0m={\n",
      "    edge_index=[2, 11546],\n",
      "    edge_label=[2564],\n",
      "    edge_label_index=[2, 2564]\n",
      "  },\n",
      "  \u001b[1m(director, rev_to, movie)\u001b[0m={ edge_index=[2, 4278] },\n",
      "  \u001b[1m(actor, rev_to, movie)\u001b[0m={ edge_index=[2, 11546] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15c1c21",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e03cbce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    \n",
    "class SimpleNet(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, metadata):\n",
    "        super().__init__()\n",
    "        self.encoder = to_hetero(Encoder(hidden_channels=hidden_channels, out_channels=out_channels), metadata)\n",
    "    \n",
    "    def encode(self, x_dict, edge_index_dict):\n",
    "        return self.encoder(x_dict, edge_index_dict)\n",
    "    \n",
    "    def decode(self, z1, z2, edge_label_index):\n",
    "        x1 = z1[edge_label_index[0]]\n",
    "        x2 = z2[edge_label_index[1]]\n",
    "        return (x1 * x2).sum(dim=-1)\n",
    "    \n",
    "    \n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, metadata):\n",
    "        super().__init__()\n",
    "        self.encoder = to_hetero(Encoder(hidden_channels=hidden_channels, out_channels=out_channels), metadata)\n",
    "        \n",
    "        self.W1 = nn.Linear(out_channels * 2, out_channels)\n",
    "        self.W2 = nn.Linear(out_channels, 1)\n",
    "        \n",
    "    def encode(self, x_dict, edge_index_dict):\n",
    "        return self.encoder(x_dict, edge_index_dict)\n",
    "    \n",
    "    def decode(self, z1, z2, edge_label_index):\n",
    "        z_forward = torch.cat((z1[edge_label_index[0]], z2[edge_label_index[1]]), dim=1)\n",
    "        out1 = self.W2(F.relu(self.W1(z_forward)).squeeze()).squeeze()\n",
    "        \n",
    "        z_reverse = torch.cat((z2[edge_label_index[1]], z1[edge_label_index[0]]), dim=1)\n",
    "        out2 = self.W2(F.relu(self.W1(z_reverse)).squeeze()).squeeze()\n",
    "        \n",
    "        return (out1 + out2) / 2\n",
    "    \n",
    "    \n",
    "simple_model = SimpleNet(hidden_channels=128, out_channels=32, metadata=train_data.metadata()).to(device)\n",
    "simple_optimizer = torch.optim.Adam(params=simple_model.parameters(), lr=5e-3, weight_decay=1e-4)\n",
    "\n",
    "model = Net(hidden_channels=128, out_channels=32, metadata=train_data.metadata()).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=5e-3, weight_decay=1e-4)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89d020eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, data, key):\n",
    "    start, _, end = key\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=data.edge_index_dict[key], \n",
    "        num_nodes=(data.x_dict[start].shape[0], data.x_dict[end].shape[0]),\n",
    "        num_neg_samples=data.edge_label_index_dict[key].shape[1], \n",
    "        method='sparse'\n",
    "    )\n",
    "    \n",
    "    edge_label_index = data.edge_label_index_dict[key]\n",
    "    edge_label_index = torch.cat([edge_label_index, neg_edge_index], dim=-1)\n",
    "    \n",
    "    edge_label = data.edge_label_dict[key]\n",
    "    edge_label = torch.cat([edge_label, edge_label.new_zeros(neg_edge_index.size(1))], dim=0)\n",
    "    \n",
    "    out = model.decode(z[start], z[end], edge_label_index)\n",
    "    loss = criterion(out, edge_label)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data, key):\n",
    "    start, _, end = key\n",
    "    model.eval()\n",
    "    z = model.encode(data.x_dict, data.edge_index_dict)\n",
    "    out = model.decode(z[start], z[end], data.edge_label_index_dict[key]).view(-1).sigmoid()\n",
    "    a, b = data.edge_label_dict[key].cpu().numpy(), out.cpu().numpy()\n",
    "    c = (out > 0.5).float().cpu().numpy()\n",
    "        \n",
    "    return roc_auc_score(a, b), accuracy_score(a, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dab16a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6932, Val: 0.5290 0.4836, Test: 0.5204 0.4614\n",
      "Epoch: 002, Loss: 0.6810, Val: 0.6054 0.5491, Test: 0.5938 0.5484\n",
      "Epoch: 003, Loss: 0.6366, Val: 0.6695 0.6225, Test: 0.6490 0.6014\n",
      "Epoch: 004, Loss: 0.5971, Val: 0.6283 0.5398, Test: 0.6098 0.5218\n",
      "Epoch: 005, Loss: 0.7375, Val: 0.6905 0.6373, Test: 0.6647 0.6170\n",
      "Epoch: 006, Loss: 0.5302, Val: 0.6588 0.5554, Test: 0.6395 0.5394\n",
      "Epoch: 007, Loss: 0.5959, Val: 0.6670 0.5421, Test: 0.6496 0.5277\n",
      "Epoch: 008, Loss: 0.5899, Val: 0.7122 0.5913, Test: 0.6886 0.5768\n",
      "Epoch: 009, Loss: 0.5526, Val: 0.7354 0.6482, Test: 0.7191 0.6342\n",
      "Epoch: 010, Loss: 0.5196, Val: 0.7291 0.6591, Test: 0.7193 0.6580\n",
      "Epoch: 011, Loss: 0.4894, Val: 0.7150 0.6490, Test: 0.7063 0.6447\n",
      "Epoch: 012, Loss: 0.4675, Val: 0.7115 0.6435, Test: 0.7035 0.6400\n",
      "Epoch: 013, Loss: 0.4623, Val: 0.7269 0.6630, Test: 0.7201 0.6587\n",
      "Epoch: 014, Loss: 0.4163, Val: 0.7426 0.6724, Test: 0.7368 0.6673\n",
      "Epoch: 015, Loss: 0.3772, Val: 0.7472 0.6599, Test: 0.7413 0.6541\n",
      "Epoch: 016, Loss: 0.3653, Val: 0.7485 0.6591, Test: 0.7426 0.6548\n",
      "Epoch: 017, Loss: 0.3408, Val: 0.7513 0.6747, Test: 0.7455 0.6685\n",
      "Epoch: 018, Loss: 0.3126, Val: 0.7525 0.6786, Test: 0.7468 0.6743\n",
      "Epoch: 019, Loss: 0.2820, Val: 0.7570 0.6763, Test: 0.7516 0.6697\n",
      "Epoch: 020, Loss: 0.2632, Val: 0.7632 0.6513, Test: 0.7576 0.6494\n",
      "Epoch: 021, Loss: 0.2516, Val: 0.7606 0.6646, Test: 0.7548 0.6607\n",
      "Epoch: 022, Loss: 0.2213, Val: 0.7606 0.6568, Test: 0.7535 0.6587\n",
      "Epoch: 023, Loss: 0.2042, Val: 0.7669 0.6427, Test: 0.7568 0.6330\n",
      "Epoch: 024, Loss: 0.1943, Val: 0.7680 0.6404, Test: 0.7569 0.6349\n",
      "Epoch: 025, Loss: 0.1746, Val: 0.7638 0.6630, Test: 0.7535 0.6525\n",
      "Epoch: 026, Loss: 0.1708, Val: 0.7682 0.6490, Test: 0.7578 0.6377\n",
      "Epoch: 027, Loss: 0.1580, Val: 0.7675 0.6521, Test: 0.7579 0.6443\n",
      "Epoch: 028, Loss: 0.1450, Val: 0.7704 0.6365, Test: 0.7611 0.6365\n",
      "Epoch: 029, Loss: 0.1364, Val: 0.7716 0.6248, Test: 0.7625 0.6318\n",
      "Epoch: 030, Loss: 0.1277, Val: 0.7700 0.6396, Test: 0.7613 0.6443\n",
      "Epoch: 031, Loss: 0.1222, Val: 0.7751 0.6123, Test: 0.7649 0.6190\n",
      "Epoch: 032, Loss: 0.1184, Val: 0.7715 0.6513, Test: 0.7609 0.6525\n",
      "Epoch: 033, Loss: 0.1168, Val: 0.7783 0.6108, Test: 0.7666 0.6190\n",
      "Epoch: 034, Loss: 0.1074, Val: 0.7770 0.6186, Test: 0.7670 0.6275\n",
      "Epoch: 035, Loss: 0.0970, Val: 0.7759 0.6069, Test: 0.7679 0.6229\n",
      "Epoch: 036, Loss: 0.0974, Val: 0.7767 0.5944, Test: 0.7696 0.6151\n",
      "Epoch: 037, Loss: 0.0911, Val: 0.7743 0.6178, Test: 0.7675 0.6318\n",
      "Epoch: 038, Loss: 0.0925, Val: 0.7775 0.5874, Test: 0.7709 0.6073\n",
      "Epoch: 039, Loss: 0.0862, Val: 0.7741 0.6154, Test: 0.7672 0.6338\n",
      "Epoch: 040, Loss: 0.0902, Val: 0.7781 0.5796, Test: 0.7714 0.5991\n",
      "Epoch: 041, Loss: 0.0815, Val: 0.7767 0.6030, Test: 0.7693 0.6213\n",
      "Epoch: 042, Loss: 0.0785, Val: 0.7787 0.5858, Test: 0.7713 0.6053\n",
      "Epoch: 043, Loss: 0.0731, Val: 0.7805 0.5796, Test: 0.7724 0.5979\n",
      "Epoch: 044, Loss: 0.0723, Val: 0.7793 0.6076, Test: 0.7697 0.6193\n",
      "Epoch: 045, Loss: 0.0754, Val: 0.7826 0.5796, Test: 0.7731 0.5956\n",
      "Epoch: 046, Loss: 0.0725, Val: 0.7814 0.5803, Test: 0.7733 0.5959\n",
      "Epoch: 047, Loss: 0.0671, Val: 0.7785 0.5975, Test: 0.7716 0.6123\n",
      "Epoch: 048, Loss: 0.0693, Val: 0.7791 0.5741, Test: 0.7746 0.5866\n",
      "Epoch: 049, Loss: 0.0655, Val: 0.7780 0.5858, Test: 0.7738 0.6030\n",
      "Epoch: 050, Loss: 0.0637, Val: 0.7784 0.5811, Test: 0.7742 0.5928\n",
      "Final Test: 0.7731 0.5956\n"
     ]
    }
   ],
   "source": [
    "key = (\"movie\", \"to\", \"actor\")\n",
    "start, _, end = key\n",
    "\n",
    "best_val_auc = final_test_auc = final_test_acc = 0\n",
    "for epoch in range(1, 51):\n",
    "    loss = train(simple_model, simple_optimizer, train_data, key)\n",
    "    val_auc, val_acc = test(simple_model, val_data, key)\n",
    "    test_auc, test_acc = test(simple_model, test_data, key)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "        final_test_acc = test_acc\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f} {val_acc:.4f}, Test: {test_auc:.4f} {test_acc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f} {final_test_acc:.4f}')\n",
    "\n",
    "simple_z = simple_model.encode(test_data.x_dict, test_data.edge_index_dict)\n",
    "simple_final_edge_index = simple_model.decode(simple_z[start], simple_z[end], test_data.edge_label_index_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab773d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6972, Val: 0.4625 0.4930, Test: 0.4548 0.4992\n",
      "Epoch: 002, Loss: 0.6920, Val: 0.4758 0.4548, Test: 0.4666 0.4555\n",
      "Epoch: 003, Loss: 0.6895, Val: 0.5091 0.4540, Test: 0.4985 0.4497\n",
      "Epoch: 004, Loss: 0.6848, Val: 0.5497 0.5351, Test: 0.5333 0.5257\n",
      "Epoch: 005, Loss: 0.6765, Val: 0.5705 0.5538, Test: 0.5491 0.5488\n",
      "Epoch: 006, Loss: 0.6664, Val: 0.5851 0.5569, Test: 0.5611 0.5519\n",
      "Epoch: 007, Loss: 0.6522, Val: 0.6035 0.5858, Test: 0.5759 0.5651\n",
      "Epoch: 008, Loss: 0.6329, Val: 0.6191 0.5944, Test: 0.5905 0.5722\n",
      "Epoch: 009, Loss: 0.6122, Val: 0.6342 0.5991, Test: 0.6063 0.5905\n",
      "Epoch: 010, Loss: 0.5985, Val: 0.6378 0.6014, Test: 0.6128 0.5909\n",
      "Epoch: 011, Loss: 0.5781, Val: 0.6570 0.6334, Test: 0.6350 0.6123\n",
      "Epoch: 012, Loss: 0.5651, Val: 0.6578 0.6209, Test: 0.6367 0.6197\n",
      "Epoch: 013, Loss: 0.5410, Val: 0.6582 0.6225, Test: 0.6359 0.6178\n",
      "Epoch: 014, Loss: 0.5319, Val: 0.6709 0.6342, Test: 0.6495 0.6193\n",
      "Epoch: 015, Loss: 0.5067, Val: 0.6743 0.6279, Test: 0.6524 0.6131\n",
      "Epoch: 016, Loss: 0.4897, Val: 0.6680 0.6342, Test: 0.6441 0.6193\n",
      "Epoch: 017, Loss: 0.4740, Val: 0.6689 0.6318, Test: 0.6454 0.6279\n",
      "Epoch: 018, Loss: 0.4604, Val: 0.6726 0.6248, Test: 0.6498 0.6260\n",
      "Epoch: 019, Loss: 0.4460, Val: 0.6707 0.6271, Test: 0.6467 0.6225\n",
      "Epoch: 020, Loss: 0.4226, Val: 0.6672 0.6248, Test: 0.6432 0.6170\n",
      "Epoch: 021, Loss: 0.4216, Val: 0.6687 0.6186, Test: 0.6447 0.6154\n",
      "Epoch: 022, Loss: 0.4045, Val: 0.6666 0.6131, Test: 0.6434 0.6080\n",
      "Epoch: 023, Loss: 0.3931, Val: 0.6631 0.6193, Test: 0.6413 0.6143\n",
      "Epoch: 024, Loss: 0.3895, Val: 0.6632 0.6076, Test: 0.6440 0.6123\n",
      "Epoch: 025, Loss: 0.3795, Val: 0.6627 0.5975, Test: 0.6462 0.6131\n",
      "Epoch: 026, Loss: 0.3723, Val: 0.6593 0.6123, Test: 0.6449 0.6217\n",
      "Epoch: 027, Loss: 0.3718, Val: 0.6600 0.5991, Test: 0.6477 0.6182\n",
      "Epoch: 028, Loss: 0.3555, Val: 0.6627 0.6022, Test: 0.6508 0.6115\n",
      "Epoch: 029, Loss: 0.3595, Val: 0.6626 0.6030, Test: 0.6502 0.6193\n",
      "Epoch: 030, Loss: 0.3553, Val: 0.6637 0.6147, Test: 0.6520 0.6232\n",
      "Epoch: 031, Loss: 0.3395, Val: 0.6629 0.5928, Test: 0.6555 0.6178\n",
      "Epoch: 032, Loss: 0.3424, Val: 0.6608 0.6084, Test: 0.6536 0.6221\n",
      "Epoch: 033, Loss: 0.3299, Val: 0.6608 0.6170, Test: 0.6523 0.6221\n",
      "Epoch: 034, Loss: 0.3291, Val: 0.6605 0.6069, Test: 0.6565 0.6205\n",
      "Epoch: 035, Loss: 0.3217, Val: 0.6600 0.5975, Test: 0.6579 0.6151\n",
      "Epoch: 036, Loss: 0.3124, Val: 0.6583 0.6014, Test: 0.6551 0.6178\n",
      "Epoch: 037, Loss: 0.3141, Val: 0.6607 0.6076, Test: 0.6561 0.6154\n",
      "Epoch: 038, Loss: 0.3139, Val: 0.6652 0.6014, Test: 0.6605 0.6115\n",
      "Epoch: 039, Loss: 0.3105, Val: 0.6665 0.6037, Test: 0.6609 0.6096\n",
      "Epoch: 040, Loss: 0.2983, Val: 0.6664 0.6092, Test: 0.6595 0.6135\n",
      "Epoch: 041, Loss: 0.2984, Val: 0.6659 0.6022, Test: 0.6619 0.6084\n",
      "Epoch: 042, Loss: 0.2944, Val: 0.6659 0.5967, Test: 0.6637 0.6104\n",
      "Epoch: 043, Loss: 0.2957, Val: 0.6661 0.5959, Test: 0.6624 0.6096\n",
      "Epoch: 044, Loss: 0.2872, Val: 0.6650 0.5998, Test: 0.6604 0.6100\n",
      "Epoch: 045, Loss: 0.2787, Val: 0.6653 0.5858, Test: 0.6599 0.6045\n",
      "Epoch: 046, Loss: 0.2801, Val: 0.6664 0.5874, Test: 0.6580 0.6022\n",
      "Epoch: 047, Loss: 0.2781, Val: 0.6666 0.5913, Test: 0.6555 0.6080\n",
      "Epoch: 048, Loss: 0.2749, Val: 0.6667 0.5827, Test: 0.6549 0.6049\n",
      "Epoch: 049, Loss: 0.2722, Val: 0.6672 0.5827, Test: 0.6547 0.5932\n",
      "Epoch: 050, Loss: 0.2749, Val: 0.6672 0.5905, Test: 0.6538 0.6018\n",
      "Final Test: 0.6524 0.6131\n"
     ]
    }
   ],
   "source": [
    "key = (\"movie\", \"to\", \"actor\")\n",
    "start, _, end = key\n",
    "\n",
    "best_val_auc = final_test_auc = final_test_acc = 0\n",
    "for epoch in range(1, 51):\n",
    "    loss = train(model, optimizer, train_data, key)\n",
    "    val_auc, val_acc = test(model, val_data, key)\n",
    "    test_auc, test_acc = test(model, test_data, key)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "        final_test_acc = test_acc\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f} {val_acc:.4f}, Test: {test_auc:.4f} {test_acc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f} {final_test_acc:.4f}')\n",
    "\n",
    "z = model.encode(test_data.x_dict, test_data.edge_index_dict)\n",
    "final_edge_index = model.decode(z[start], z[end], test_data.edge_label_index_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6bdde4",
   "metadata": {},
   "source": [
    "## SubgraphX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a60dc185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "706acc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3057, 3242])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.edge_label_index_dict[(\"movie\", \"to\", \"actor\")][:, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2402cd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 11546])\n",
      "torch.Size([2, 4278])\n"
     ]
    }
   ],
   "source": [
    "node_1 = 2344\n",
    "node_2 = 4044\n",
    "\n",
    "movie_to_actor_index = test_data.edge_index_dict[(\"movie\", \"to\", \"actor\")]\n",
    "movie_to_director_index = test_data.edge_index_dict[(\"movie\", \"to\", \"director\")]\n",
    "\n",
    "print(movie_to_actor_index.shape)\n",
    "print(movie_to_director_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03c95398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie actors {4044, 476, 2126}\n",
      "movie director {719}\n",
      "actor movies {2208, 2818, 551, 2344, 280}\n"
     ]
    }
   ],
   "source": [
    "node_1_actor_neighbors = set(movie_to_actor_index[:, movie_to_actor_index[0] == node_1][1].cpu().numpy())\n",
    "node_1_director_neighbors = set(movie_to_director_index[:, movie_to_director_index[0] == node_1][1].cpu().numpy())\n",
    "\n",
    "print(\"movie actors\", node_1_actor_neighbors)\n",
    "print(\"movie director\", node_1_director_neighbors)\n",
    "\n",
    "node_2_actor_neighbors = set(movie_to_actor_index[:, movie_to_actor_index[1] == node_2][0].cpu().numpy())\n",
    "\n",
    "print(\"actor movies\", node_2_actor_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5474dde3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhijit\\AppData\\Local\\Temp\\ipykernel_13432\\1742952322.py:8: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorAdvancedIndexing.cpp:1582.)\n",
      "  S_filter[(sub_edge_mask) & (np.random.random(sub_edge_mask.shape[0]) > 0.5)] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2208 \t 0.22202 \t 0.44816 \t 0.49541\n",
      "2818 \t 3.01895 \t 2.8313 \t 1.06627\n",
      "551 \t 1.21486 \t 0.4297 \t 2.82721\n",
      "2344 \t 2.62995 \t 3.02644 \t 0.86899\n",
      "280 \t -0.56216 \t 0.11493 \t -4.89135\n"
     ]
    }
   ],
   "source": [
    "T = 5\n",
    "for neighbor in node_2_actor_neighbors:\n",
    "    pred_diffs = []\n",
    "    sub_edge_mask = movie_to_actor_index[1] == node_2\n",
    "    for t in range(T):\n",
    "        S_filter = torch.zeros(movie_to_actor_index.shape[1], dtype=bool)\n",
    "        S_filter[sub_edge_mask] = True\n",
    "        S_filter[(sub_edge_mask) & (np.random.random(sub_edge_mask.shape[0]) > 0.5)] = False\n",
    "        S_filter[(movie_to_actor_index[0] == neighbor)] = False\n",
    "        \n",
    "        temp_edge_index_dict = {k: v for k, v in test_data.edge_index_dict.items()}\n",
    "        temp_edge_index_dict[(\"movie\", \"to\", \"actor\")] = movie_to_actor_index[:, S_filter]\n",
    "        \n",
    "        old_z = model.encode(test_data.x_dict, temp_edge_index_dict)\n",
    "        old_pred = model.decode(old_z[\"movie\"], old_z[\"actor\"], torch.tensor([[node_1], [node_2]]))\n",
    "        \n",
    "        S_filter[(movie_to_actor_index[0] == neighbor)] = True\n",
    "        temp_edge_index_dict = {k: v for k, v in test_data.edge_index_dict.items()}\n",
    "        temp_edge_index_dict[(\"movie\", \"to\", \"actor\")] = movie_to_actor_index[:, S_filter]\n",
    "        \n",
    "        new_z = model.encode(test_data.x_dict, temp_edge_index_dict)\n",
    "        new_pred = model.decode(new_z[\"movie\"], new_z[\"actor\"], torch.tensor([[node_1], [node_2]]))\n",
    "        \n",
    "        pred_diff = (new_pred - old_pred)\n",
    "        pred_diffs.append(pred_diff.item())\n",
    "    diff_avg, diff_std = sum(pred_diffs) / len(pred_diffs), statistics.stdev(pred_diffs) / np.sqrt(T)\n",
    "    print(neighbor, \"\\t\", round(diff_avg, 5), \"\\t\", round(diff_std, 5), \"\\t\", round(diff_avg / diff_std, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d68b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

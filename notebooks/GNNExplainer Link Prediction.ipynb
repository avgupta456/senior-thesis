{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68d27b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhijit\\Documents\\GitHub\\cpsc490\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b36b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(\n",
    "        num_val=0.05, \n",
    "        num_test=0.1, \n",
    "        is_undirected=True, \n",
    "        add_negative_train_samples=False\n",
    "    ),\n",
    "])\n",
    "\n",
    "dataset = Planetoid(\"../data/Cora\", name='Cora', transform=transform)\n",
    "\n",
    "# After applying the `RandomLinkSplit` transform, the data is transformed from\n",
    "# a data object to a list of tuples (train_data, val_data, test_data), with\n",
    "# each element representing the corresponding split.\n",
    "\n",
    "train_data, val_data, test_data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afe5b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        \n",
    "        # self.W1 = nn.Linear(out_channels * 2, out_channels)\n",
    "        # self.W2 = nn.Linear(out_channels, 1)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        # z = torch.cat((z[edge_label_index[0]], z[edge_label_index[1]]), dim=1)\n",
    "        # return self.W2(F.relu(self.W1(z)).squeeze())\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "\n",
    "model = Net(dataset.num_features, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92f8c87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 0.6896, Val: 0.7359, Test: 0.7443\n",
      "Epoch: 020, Loss: 0.6356, Val: 0.7746, Test: 0.7566\n",
      "Epoch: 030, Loss: 0.5678, Val: 0.7890, Test: 0.7659\n",
      "Epoch: 040, Loss: 0.5294, Val: 0.8271, Test: 0.8149\n",
      "Epoch: 050, Loss: 0.4920, Val: 0.8598, Test: 0.8724\n",
      "Epoch: 060, Loss: 0.4764, Val: 0.8680, Test: 0.8903\n",
      "Epoch: 070, Loss: 0.4601, Val: 0.8709, Test: 0.9002\n",
      "Epoch: 080, Loss: 0.4508, Val: 0.8761, Test: 0.9033\n",
      "Epoch: 090, Loss: 0.4461, Val: 0.8961, Test: 0.9085\n",
      "Epoch: 100, Loss: 0.4506, Val: 0.8922, Test: 0.9124\n",
      "Epoch: 110, Loss: 0.4428, Val: 0.8981, Test: 0.9140\n",
      "Epoch: 120, Loss: 0.4411, Val: 0.8978, Test: 0.9166\n",
      "Epoch: 130, Loss: 0.4376, Val: 0.8983, Test: 0.9172\n",
      "Epoch: 140, Loss: 0.4256, Val: 0.9068, Test: 0.9208\n",
      "Epoch: 150, Loss: 0.4249, Val: 0.9116, Test: 0.9229\n",
      "Epoch: 160, Loss: 0.4263, Val: 0.9131, Test: 0.9233\n",
      "Epoch: 170, Loss: 0.4201, Val: 0.9125, Test: 0.9243\n",
      "Epoch: 180, Loss: 0.4204, Val: 0.9083, Test: 0.9224\n",
      "Epoch: 190, Loss: 0.4118, Val: 0.9091, Test: 0.9227\n",
      "Epoch: 200, Loss: 0.4160, Val: 0.9092, Test: 0.9203\n",
      "Final Test: 0.9238\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "z = model.encode(test_data.x, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdc1b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
